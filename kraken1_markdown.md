---


---

<h1 id="kraken-1.0">Kraken 1.0</h1>
<ul>
<li><strong>Author</strong>: Dreycey Albin</li>
<li><strong>Date</strong>:  05/13/2019</li>
<li><strong>Updates</strong>:</li>
<li><strong>Description</strong>: This is a super concise overview for using Kraken. Kraken 1.0 is a software used for taxonomic classification of a sample given the reads.</li>
<li><strong>documentation (website)</strong>:</li>
<li><strong>documentation (website-manual)</strong>: <a href="http://ccb.jhu.edu/software/kraken/MANUAL.html">KRAKENMANUAL.html</a></li>
</ul>
<h2 id="installing">Installing</h2>
<h3 id="install-source-using-the-following-commands">install source using the following commands:</h3>
<pre><code>git clone https://github.com/DerrickWood/kraken;
cd kraken;
./install_kraken.sh Kraken_installation_directory;
</code></pre>
<h3 id="install-kraken-singularity-container-using-the-following-commands">Install Kraken singularity container using the following commands:</h3>
<pre><code>singularity pull docker://quay.io/biocontainers/kraken:0.10.6_eaf8fb68--pl5.22.0_4;
</code></pre>
<p>Ran the tool using the singularoty image but it produced the following error:</p>
<pre><code>singularity exec -B {PWD}:/tmp/ kraken-0.10.6_eaf8fb68--pl5.22.0_4.simg kraken --db //rdf/Dreycey/krakenDB --threads 10 --fastq-input paired_1.fastq paired_2.fastq
</code></pre>
<pre><code>WARNING: Not mounting requested bind point (already mounted in container): /tmp/
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
LANGUAGE = (unset),
LC_ALL = (unset),
LANG = "en_US.UTF-8"
are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
kraken: database ("../../../../../rdf/Dreycey/krakenDB") does not contain necessary file database.kdb
</code></pre>
<p>However the following command worked fine:</p>
<pre><code>./kraken --db //rdf/Dreycey/krakenDB --threads 10 --fastq-input //rdf/Dreycey/aagard_kraken/aagaard_samples/NCS_033_INTRO3_paired_1.fastq  //rdf/Dreycey/aagard_kraken/aagaard_samples/NCS_033_INTRO3_paired_2.fastq
</code></pre>
<p>Transfering this over was filling up all room on the scratch. Turns out the reason why is because:</p>
<pre><code>du -h //rdf/Dreycey/krakenDB
</code></pre>
<pre><code>311M  //rdf/Dreycey/krakenDB/taxonomy
454G  //rdf/Dreycey/krakenDB
</code></pre>
<h2 id="notes-on-commands-detailed">Notes on commands (detailed)</h2>
<h3 id="typical-run-without-extra-information">(1) Typical run without extra information:</h3>
<p>for fasta:</p>
<pre><code>kraken --db $DBNAME --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta seqs.fa --output krakenoutput/krakenoutifle.txt
</code></pre>
<p>for fastq:</p>
<pre><code>kraken --db $DBNAME --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta --fastq-input seqs.fq --output krakenoutput/krakenoutifle.txt
</code></pre>
<p>for paired-end reads:</p>
<pre><code>kraken --db $DBNAME --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta --paired seqs_1.fq seqs_2.fq--output krakenoutput/krakenoutifle.txt
</code></pre>
<p><strong>Note</strong>: <strong>Kraken will automatically attempt to determine the file type if not specified.</strong> --gzip-compressed and --bzip2-compressed are also available.</p>
<p>This will run Kraken normally, using the $DBNAME database, will use NUM threads, and give files with classified and unclassified sequences. One can imagine then sending these unclassified into a different program.</p>
<h3 id="for-a-super-quick-run-of-the-database">(2) For a super quick run of the database:</h3>
<p>Lets say we have paired end reads, the following command can be used for a QUICK run:<br>
for paired-end reads:</p>
<pre><code>kraken --db $DBNAME --quick --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta --paired seqs_1.fq seqs_2.fq--output krakenoutput/krakenoutifle.txt
</code></pre>
<p>If we want a higher precision, one may use:</p>
<pre><code>kraken --db $DBNAME --quick --min-hits 3 --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta --paired seqs_1.fq seqs_2.fq--output krakenoutput/krakenoutifle.txt
</code></pre>
<p>NOTE: The --quick flag stops querying k-mers in a given sequence after the first database hit. The --min-hits NUM option allows for a minimum to be specified, other than just one hit.</p>
<h3 id="for-increasing-the-precision----quick-">(3) For increasing the precision ( --quick )</h3>
<p>One may also make thresholds for the output report generated by Kraken. This would increase the precision, but it will also push the classifications up the taxonomy tree which will decrease the accuracy of classifying at lower taxonomy levels.</p>
<pre><code>kraken-filter [--db KRAKEN_DB_NAME] [--threshold NUM] &lt;kraken output file(s)&gt;
</code></pre>
<h3 id="generating-a-report-file-for-kraken-1.0">(4) Generating a report file for Kraken 1.0</h3>
<p>It is recommended to also generate a report file for the output of Kraken. This can thereafter be further parsed, or used in Bracken. Note that this is a flag/switch for Kraken 2.0.</p>
<pre><code>kraken-report --db $DBNAME kraken.output
</code></pre>
<p>The above will only show classified taxa. If one wishes to easily parse multiple report files, the following script is recommended:</p>
<pre><code>kraken-report --db $DBNAME --show-zeros sort -nf5 kraken.output
</code></pre>
<p>One may also have a report file similiar to MetaPhlAn using:</p>
<pre><code>kraken-mpa-report -db krakenDB kraken_1.output kraken_2.output ... kraken_n.output
</code></pre>
<h2 id="databases-used-for-kraken1">Databases used for Kraken1</h2>
<h3 id="off-the-shelve-databases">“Off the shelve” databases</h3>
<ul>
<li>MiniKraken (option #1): 4GB – 99% precision, 65% accuracy</li>
</ul>
<pre><code>wget http://ccb.jhu.edu/software/kraken/dl/minikraken_20171019_4GB.tgz
</code></pre>
<ul>
<li>MiniKraken (option #2): 8GB – 99% precision, 65% accuracy</li>
</ul>
<pre><code>wget http://ccb.jhu.edu/software/kraken/dl/minikraken_20171019_8GB.tgz
</code></pre>
<ul>
<li>Typical full krakenDB: 500GB – 99% precision, 91% accuracy</li>
</ul>
<pre><code>kraken-build --standard --threads 24 --db kraken1_DB --clean
</code></pre>
<p>NOTE: <em>The</em> <strong>" --clean "</strong> <em>switch removes unnecessary intermediate files</em></p>
<h3 id="building-a-custom-kraken1-database">Building a <em>custom</em> kraken1 database</h3>
<h4 id="choosing-libraries">Choosing libraries</h4>
<ul>
<li>Step 1: Create the NCBI taxonomy folder:</li>
</ul>
<pre><code> kraken-build --download-taxonomy --db kraken1_DB
</code></pre>
<ul>
<li>
<p>Step 2: Create a genomic library:<br>
Using the following commands, any of the genomic libraries of interest may be created:</p>
</li>
<li>
<p>Make the library for bacteria (RefSeq)</p>
</li>
</ul>
<pre><code> kraken-build --download-library bacteria --db kraken1_DB
</code></pre>
<ul>
<li>Make the library for archaea (RefSeq)</li>
</ul>
<pre><code> kraken-build --download-library archaea --db kraken1_DB
</code></pre>
<ul>
<li>Make the library for plasmid (RefSeq)</li>
</ul>
<pre><code> kraken-build --download-library plasmid --db kraken1_DB 
</code></pre>
<ul>
<li>Make the library for viral (RefSeq)</li>
</ul>
<pre><code> kraken-build --download-library viral --db kraken1_DB 
</code></pre>
<ul>
<li>Make the library for human (GRCh38 human genome)</li>
</ul>
<pre><code> kraken-build --download-library human --db kraken1_DB 
</code></pre>
<p>From here, it can really depend on what the user is looking for in a sample. Having the size of each of these individual databases would probably be best, however, downloading only the genomic libraries of interest is sure to save space. <strong>Potentially using both the bacterial library and plasmid library in combination with minikraken could be a method to have both broad and comprehensive analysis.</strong></p>
<h4 id="adding-custom-genomes-to-the-database">Adding custom genomes to the database</h4>
<p>The custom files input into the database must be in fasta or multi fasta file format. These must contain NCBI information in the header, or explicitly assigned NCBI information.<br>
(The following is from the manual linked in the header of this file)</p>
<ul>
<li>NCBI information in the header</li>
</ul>
<pre><code> &gt;32630  Adapter sequence
CAAGCAGAAGACGGCATACGAGATCTTCGAGTGACTGGAGTTCCTTGGCACCCGAGAATTCCA
</code></pre>
<ul>
<li>explicitly assigned NCBI information</li>
</ul>
<pre><code> &gt;sequence16|kraken:taxid|32630  Adapter sequence
CAAGCAGAAGACGGCATACGAGATCTTCGAGTGACTGGAGTTCCTTGGCACCCGAGAATTCCA
</code></pre>
<ul>
<li>this is how you add the above sequences to the library:</li>
</ul>
<pre><code>kraken-build --add-to-library fastafile.fa --db kraken1_DB
</code></pre>
<ul>
<li>A list of files in a directory may be added using the following bash command (provided in the kraken 1.0 manual):</li>
</ul>
<pre><code>for file in chr*.fa
do
    kraken-build --add-to-library $file --db kraken1_DB 
done
</code></pre>
<h4 id="final-step-building-the-custom-database">Final step: building the custom database</h4>
<pre><code> kraken-build --build --db $DBNAME --threads 24 --kmer-len 31 --minimizer-len 15 --clean
</code></pre>
<p>Here it may be interesting to deviate to a different kmer or minimizer length, depending on what works the best. (although it is assumed the creators tried many different parameter setting before landing upon these defaults)</p>
<h4 id="building-a-minikraken-database-of-your-own">Building a miniKraken database of your own!!</h4>
<p>You can also shrink a database that you have for Kraken! This effectively allows you to create a minikraken database using an existing larger database.</p>
<p>There are two ways this can be done:<br>
(1) <strong>before</strong> building the larger database<br>
(2) <strong>after</strong> building the larger database</p>
<p>(1) To build the minikrakenDB <strong>before</strong>:</p>
<pre><code> kraken-build --build --db minikraken1_DB --threads 24 --kmer-len 31 --minimizer-len 15 --clean --max-db-size &lt;Max size in GB&gt;
</code></pre>
<p>OR</p>
<pre><code>kraken-build --standard --threads 24 --db kraken1_DB --clean --clean --max-db-size &lt;Max size in GB&gt;
</code></pre>
<p>NOTE: <em>The</em> <strong>" --max-db-size"</strong> <em>switch give the max size for the database in GB</em></p>
<p>(2) To build the minikrakenDB <strong>after</strong>:</p>
<pre><code> kraken-build --shrink 10000 --db kraken1_DB --new-db minikraken
</code></pre>
<p>NOTE: <em>The</em> <strong>" --shrink"</strong> <em>switch give the number of kmers that will be added to the database</em></p>
<h2 id="parameters-that-can-be-used">Parameters that can be used:</h2>
<pre><code>Options:
--db NAME Name for Kraken DB
(default: none)
--threads NUM Number of threads (default: 1)
--fasta-input Input is FASTA format
--fastq-input Input is FASTQ format
--gzip-compressed Input is gzip compressed
--bzip2-compressed  Input is bzip2 compressed
--quick Quick operation (use first hit or hits)
--min-hits NUM  In quick op., number of hits req'd for classification
NOTE: this is ignored if --quick is not specified
--unclassified-out FILENAME
Print unclassified sequences to filename
--classified-out FILENAME
Print classified sequences to filename
--output FILENAME Print output to filename (default: stdout); "-" will
suppress normal output
--only-classified-output
Print no Kraken output for unclassified sequences
--preload Loads DB into memory before classification
--paired  The two filenames provided are paired-end reads
--check-names Ensure each pair of reads have names that agree
with each other; ignored if --paired is not specified
--help  Print this message
--version Print version information
</code></pre>
<h2 id="kraken_1-for-snakemake">Kraken_1 for Snakemake</h2>
<h2 id="bash-script">Bash script</h2>
<h3 id="install-docker-container">Install docker container</h3>
<p>singularity pull docker://quay.io/biocontainers/kraken:1.1.1–pl526h6bb024c_0;</p>
<h3 id="install-minikrakendb">Install minikrakenDB</h3>
<p>wget <a href="https://ccb.jhu.edu/software/kraken/dl/minikraken_20171019_8GB.tgz;">https://ccb.jhu.edu/software/kraken/dl/minikraken_20171019_8GB.tgz;</a><br>
tar -zxvf minikraken_20171019_8GB.tgz;<br>
mv  minikraken_20171019_8GB kraken1DB;<br>
rm minikraken_20171019_8GB.tgz;</p>
<h3 id="install-example-data-to-use">Install example data to use</h3>
<p>//rdf/software/sratoolkit.2.9.6-ubuntu64/bin/fastq-dump SRX200675 --split-files;<br>
//rdf/software/sratoolkit.2.9.6-ubuntu64/bin/fastq-dump SRX200676 --split-files;</p>
<h3 id="running-kraken_1">Running Kraken_1</h3>
<h4 id="we-will-use-the-general-command-below">We will use the general command below:</h4>
<p>kraken --db $DBNAME --threads NUM --classified-out classified_sequences.fasta --unclassified-out unclassified_sequences.fasta --paired seqs_1.fq seqs_2.fq --output krakenoutput/krakenoutifle.txt</p>
<h4 id="here-is-the-command-for-running-the-shakya-dataset">Here is the command for running the Shakya dataset:</h4>
<p>singularity exec -B ${PWD}/:/tmp kraken-1.1.1–pl526h6bb024c_0.simg kraken --db /tmp/kraken1DB --threads 15 --classified-out /tmp/krakenoutput/classified_sequences.fasta --unclassified-out /tmp/krakenoutput/unclassified_sequences.fasta --paired /tmp/SRX200675_1.fastq /tmp/SRX200675_2.fastq --output /tmp/krakenoutput/krakenoutfile.txt;</p>
<h4 id="next-a-report-file-is-generated">Next a report file is generated:</h4>
<p>export SINGULARITY_BINDPATH=${PWD}/:/tmp;</p>
<p>singularity exec -B ${PWD}/:/tmp kraken-1.1.1–pl526h6bb024c_0.simg kraken-report --db /tmp/kraken1DB --show-zeros /tmp/krakenoutput/krakenoutfile.txt &gt; krakenoutput/krakenoutfile.report;</p>
<h4 id="users-should-have-access-to-the-following">Users should have access to the following:</h4>
<p>–threads<br>
–db<br>
–paired (which is a switch)</p>
<h4 id="notes">Notes:</h4>
<p>2 different rules (one for output file, the other for the report file)</p>

